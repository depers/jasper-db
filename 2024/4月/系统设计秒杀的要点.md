| title                            | tags          | background                                                   | auther | isSlow |
| -------------------------------- | ------------- | ------------------------------------------------------------ | ------ | ------ |
| 秒杀系统设计的要点（一）性能压测 | 系统设计/秒杀 | 之前在面试的时候，老感觉自己没有做过什么复杂或是比较高级的系统和功能，所以最近专门找了一门秒杀系统的课程，系统的学习了一个完整的秒杀项目，这里通过这篇文章对这个系统中核心的功能做一个梳理和反思。 | depers | true   |

# 开源项目

项目源码地址：[https://github.com/depers/miaosha](https://github.com/depers/miaosha)

# 压测工具Jemeter的使用

### 1. 线程组

![](../../../jasper-db/assert/线程组.png)

* **线程数**：启动多少个线程去发起请求。
* **Ramp-Up时间**：在这个时间段内启动这些线程。
* **循环次数**：如果设置为10，线程数配置成10，意思就是说10个线程，每个线程调用请求10次，整体来说就是100次。

### 2. Http请求

在【线程组】-【添加】-【取样器】-【HTTP请求】新增一个Http请求的配置。这里要勾选【使用KeepAlive】从而**减少创建/关闭多个 TCP 连接的开销**，我们能够更好的测试我们接口本身的性能。

![](../../../jasper-db/assert/Http请求.png)

此外，还需要在这样页面的【高级】选项中，选择客户端的实现是【Java】，外面的Keepalive配置才能生效。

![](../../../jasper-db/assert/客户端的实现.png)

### 3. 查看结果树

用来查看每次请求的结果。

### 4. 聚合报告

用来查看请求的耗时的统计信息。其中【吞吐量】就是我们常说的TPS。

# 发现并发容量问题

## 1. 两条常用命令

### `pstree -p [pid] | wc -l`

上面这条命令用来统计应用进程开启的线程数。下面我们来具体看下这条命令各个参数的含义：

* `pstree -p [pid]`：

    * `pstree` 是一个命令，用于以树状结构显示进程之间的关系。

    * `-p` 选项表示显示进程的 PID。

    * `[pid]`是要查看其所属进程树的进程 ID。

* `|`：这是一个管道符号，用于将`pstree`命令的输出传递给下一个命令。

* `wc -l`：

    * `wc` 是一个命令，用于统计文本的行数、单词数和字符数。

    * `-l`选项表示只统计行数。

### `top -H`

`top`命令通常用于实时监测系统的进程活动情况，包括进程的 CPU 使用率、内存占用等信息。`-H`选项表示显示线程而不是进程。通过使用`top -H`，**你可以查看系统中各个线程的资源使用情况**。这对于分析多线程应用程序的性能、排查线程相关的问题等非常有用。

这里我们需要重点关注的参数有：

* load average

    load average描述了设定时间间隔内 CPU 的平均负载。这些值是给定时间段内等待 CPU（等待阻塞）或使用 CPU 的进程数。空闲系统的负载为 0。每执行一个进程或添加一个进程到等待列表中，负载就会增加 1。

    对应一核处理器来说，0代表正常，1代表打满，1+代表等待阻塞。对于双核处理器，负载为 1 意味着 1 个核心 100% 空闲。这相当于大约 50% 的 CPU 使用率。同样，对于四核处理器来说，它代表 25% 的 CPU 使用率。

    例如`load average: 0.02, 0.04, 0.00`，就表示系统1分钟、5分钟、15分钟的CPU负载信息。

* %cpu

    %cpu表示这一行显示CPU总体信息。

    - **0.0%us**：用户态进程占用CPU时间百分比**（用户层代码）**
    - **0.7%sy**：内核占用CPU时间百分比**（系统调用）**
    - 0.0%ni：改变过优先级的进程占用CPU的百分比
    - 99.3%id：空闲CPU时间百分比
    - 0.0%wa：等待I/O的CPU时间百分比
    - 0.0%hi：CPU硬中断时间百分比
    - 0.0%si：CPU软中断时间百分比
    - 注：这里显示数据是所有cpu的平均值，如果想看每一个cpu的处理情况，按`1`即可；折叠，再次按`1`。

* Men

    Men：内存的意思。

    * 8175320kk total：物理内存总量
    * 8058868k used：使用的物理内存量
    * 116452k free：空闲的物理内存量
    * 283084k buffers：用作内核缓存的物理内存量

## 2. 修改内嵌Tomcat配置

在spring-boot-autoconfigure的`spring-configuration-metadata.json`文件中隐藏着Tomcat的关键配置，分别是：

* `server.tomcat.accept-count`

    说是**请求等待队列的长度**，当所有的请求处理线程都被用掉之后，可以继续接收请求的最大队列长度。默认是100。

* `server.tomcat.max-connections`

    **用于限制服务器可以接受的最大连接数**。或者说是服务器在任何给定时间接受和处理的最大连接数。一旦达到限制，操作系统仍然可以根据“acceptCount”属性接受连接。这个参数的默认值是8192。

    `max-connections`和`accept-count`的关系为：当连接数达到最大值`max-connections`后，系统会继续接收连接，但不会超过`accept-count`的值。

    这个参数的作用是：

    1. 控制服务器的负载：防止过多的连接导致服务器资源耗尽。
    2. 优化性能：确保服务器能够有效地处理请求。

* `server.tomcat.threads.min-spare`

    用于设置最小工作线程数。最小工作线程数指定了在 Tomcat 服务器启动时或在运行期间应保持的最小空闲线程数。默认是10，可以配置成100。这个参数和`server.tomcat.min-spare-threads`功能我的理解是一样的，但是后者的配置在2.6.x版本的Spring Boot中已经找不到了。

    这有以下几个作用：

    1. 提供快速响应：确保有一些备用线程可用于快速处理新的请求。
    2. 减少线程创建开销：避免在请求到达时频繁地创建新线程。

* `server.tomcat.threads.max`

    **最大工作线程数**。4核8G的机器，最佳配置是800个线程。默认值是200。

一个tomcat总共能受理的最大连接数理论上= **acceptCount+maxConnections**。

对于tomcat的处理能力需要调整**maxThreads**最大线程数量。

## 3. Tomcat核心参数的形象解释

下面用通过一个形象的比喻，通俗易懂的解释一下tomcat的最大线程数（maxThreads）、最大等待数（acceptCount）和最大连接数（maxConnections）三者之间的关系。

假设Tomcat是一个火锅店，火锅店主要有以下三个角色：

* acceptCount，最大等待数，这里类比为火锅店的**排号**数量。
* maxConnections，最大连接数，这里类比为火锅店的**餐桌**数量。
* maxThreads，最大线程数，这里类比为火锅店的**厨师**数量。

Tomcat接收、处理和响应请求的过程可以类比为顾客用餐的过程：

* 取号：

    * 如果餐厅有空闲的餐桌，顾客就可以直接上桌就餐。类比到Tomcat就是maxConnections连接数还没有满，Tomcat会接收该请求进行处理。
    * 如果没有空桌，顾客就需要进行排号。类比到Tomcat就是maxConnections连接数已满，需要将请求放入等待队列。
        * 如果取号人数没有达到排号的上限，则取号成功。类比到Tomcat就是acceptCount请求队列长队还没有满，可以将请求放置到队列中。
        * 如果已达上限，则取号失败。类比到Tomcat就是请求队列长度已满，此时请求就会被拒绝连接。

* 上桌

    如果餐厅有空闲的餐桌，顾客就可以直接上桌就餐。类比到Tomcat就是maxConnections连接数还没有满，Tomcat会接收该请求进行处理。

* 就餐

    顾客落座之后就会点餐，此时厨房就会去做菜。相比与顾客的数量，厨师的数量肯定是比较少的。如果就餐的人越多，厨师就会越忙不过来，这个时候就需要增加厨师。如果厨师增加到一个上限后，没有办法再新增，此时就会拖慢每个餐桌上菜的速度。也就是说如果Tomcat接收到请求之后如果请求数量超过现有线程数就会新增新的线程来处理新的请求，如果线程数量增加到一定上限之后，也就是达到maxThreads，请求处理的速度就会变慢。

# 定制化内嵌tomcat开发

待更~~

# 分布式扩展

# 多级缓存

# 页面静态化

# 缓存库存

# 事务型消息保证最终一致性

# 流量削峰

# 防刷限流

# 参考文章

* [聚焦Java性能优化 打造亿级流量秒杀系统](https://coding.imooc.com/class/338.html)
* [What is Load Average in Linux?](https://www.digitalocean.com/community/tutorials/load-average-in-linux)
* [What Is Linux Average Load? [6 Monitoring Tools Inside]](https://www.redswitches.com/blog/what-is-load-average-in-linux/)
* [top linux下的任务管理器](https://linuxtools-rst.readthedocs.io/zh-cn/latest/tool/top.html)
* [秒懂：tomcat的maxConnections、maxThreads、acceptCount 图解](https://blog.csdn.net/lililidahaoren/article/details/121696324)
* [Tomcat性能调优](https://juejin.cn/post/6850418121258303501)
* [HTTP keep-alive 二三事](https://lotabout.me/2019/Things-about-keepalive/)