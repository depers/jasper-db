| title                            | tags          | background                                                   | auther | isSlow |
| -------------------------------- | ------------- | ------------------------------------------------------------ | ------ | ------ |
| 秒杀系统设计的要点（一）性能压测 | 系统设计/秒杀 | 之前在面试的时候，老感觉自己没有做过什么复杂或是比较高级的系统和功能，所以最近专门找了一门秒杀系统的课程，系统的学习了一个完整的秒杀项目，这里通过这篇文章对这个系统中核心的功能做一个梳理和反思。 | depers | true   |

# 开源项目

项目源码地址：[https://github.com/depers/miaosha](https://github.com/depers/miaosha)

# 数据库表设计的注意点



# 压测工具Jmeter的使用

### 1. 线程组

![](../../../jasper-db/assert/线程组.png)

* **线程数**：启动多少个线程去发起请求。
* **Ramp-Up时间**：在这个时间段内启动这些线程。
* **循环次数**：如果设置为10，线程数配置成10，意思就是说10个线程，每个线程调用请求10次，整体来说就是100次。

### 2. Http请求

在【线程组】-【添加】-【取样器】-【HTTP请求】新增一个Http请求的配置。这里要勾选【使用KeepAlive】从而**减少创建/关闭多个 TCP 连接的开销**，我们能够更好的测试我们接口本身的性能。

![](../../../jasper-db/assert/Http请求.png)

此外，还需要在这样页面的【高级】选项中，选择客户端的实现是【Java】，外面的Keepalive配置才能生效。

![](../../../jasper-db/assert/客户端的实现.png)

### 3. 查看结果树

用来查看每次请求的结果。如果你只想查看错误的请求，可以勾选【Errors】选项。

![](../../assert/jmeter查看结果树.png)

### 4. 聚合报告

用来查看请求的耗时的统计信息。其中Throughput就是我们常说的TPS，Average是我们请求的平均耗时，单位是ms。

![](../../assert/jmeter汇总报告.png)

# 发现并发容量问题

## 1. 两条常用命令

### `pstree -p [pid] | wc -l`

上面这条命令用来统计应用进程开启的线程数，适用于Linux系统。下面我们来具体看下这条命令各个参数的含义：

* `pstree -p [pid]`：

    * `pstree` 是一个命令，用于以树状结构显示进程之间的关系。

    * `-p` 选项表示显示进程的 PID。

    * `[pid]`是要查看其所属进程树的进程 ID。

* `|`：这是一个管道符号，用于将`pstree`命令的输出传递给下一个命令。

* `wc -l`：

    * `wc` 是一个命令，用于统计文本的行数、单词数和字符数。

    * `-l`选项表示只统计行数。

### `top -H`

`top`命令通常用于实时监测系统的进程活动情况，包括进程的 CPU 使用率、内存占用等信息。`-H`选项表示显示线程而不是进程。通过使用`top -H`，**你可以查看系统中各个线程的资源使用情况**。这对于分析多线程应用程序的性能、排查线程相关的问题等非常有用。

这里我们需要重点关注的参数有：

* **load average**

    load average描述了设定时间间隔内 CPU 的平均负载。这些值是给定时间段内等待 CPU（等待阻塞）或使用 CPU 的进程数。空闲系统的负载为 0。每执行一个进程或添加一个进程到等待列表中，负载就会增加 1。

    对应一核处理器来说，0代表正常，1代表打满，1+代表等待阻塞。对于双核处理器，负载为 1 意味着 1 个核心 100% 空闲。这相当于大约 50% 的 CPU 使用率。同样，对于四核处理器来说，它代表 25% 的 CPU 使用率。

    例如`load average: 0.02, 0.04, 0.00`，就表示系统1分钟、5分钟、15分钟的CPU负载信息。

* **%cpu**

    %cpu表示这一行显示CPU总体信息。

    - **0.0%us**：用户态进程占用CPU时间百分比**（用户层代码）**
    - **0.7%sy**：内核占用CPU时间百分比**（系统调用）**
    - 0.0%ni：改变过优先级的进程占用CPU的百分比
    - 99.3%id：空闲CPU时间百分比
    - 0.0%wa：等待I/O的CPU时间百分比
    - 0.0%hi：CPU硬中断时间百分比
    - 0.0%si：CPU软中断时间百分比
    - 注：这里显示数据是所有cpu的平均值，如果想看每一个cpu的处理情况，按`1`即可；折叠，再次按`1`。

* **Mem**

    Mem：内存的意思。

    * 8175320kk total：物理内存总量
    * 8058868k used：使用的物理内存量
    * 116452k free：空闲的物理内存量
    * 283084k buffers：用作内核缓存的物理内存量

* **Swap**

    * 6881272k total：交换区总量
    * 4010444k used：使用的交换区量
    * 2870828k free：空闲的交换区量
    * 4336992k cached：缓冲交换区总量
    * 557684k avail Mem 表示可用内存，它指的是系统中当前可供进程使用的剩余内存量

* **进程信息**

    * PID：进程的ID
    * USER：进程所有者
    * PR：进程的优先级别，越小越优先被执行
    * VIRT：进程占用的虚拟内存
    * RES：进程占用的物理内存
    * SHR：进程使用的共享内存
    * S：进程的状态。S表示休眠，R表示正在运行，Z表示僵死状态，N表示该进程优先值为负数
    * %CPU：进程占用CPU的使用率
    * %MEM：进程使用的物理内存和总内存的百分比
    * TIME+：该进程启动后占用的总的CPU时间，即占用CPU使用时间的累加值。
    * COMMAND：进程启动命令名称

## 2. 修改内嵌Tomcat配置

在spring-boot-autoconfigure的`spring-configuration-metadata.json`文件中隐藏着Tomcat的关键配置，分别是：

* `server.tomcat.accept-count`

    说是**请求等待队列的长度**，当所有的请求处理线程都被用掉之后，可以继续接收请求的最大队列长度。默认是100。

* `server.tomcat.max-connections`

    **用于限制服务器可以接受的最大连接数**。或者说是服务器在任何给定时间接受和处理的最大连接数，这个值表示最多可以有多少个Socket 连接到Tomcat上。一旦达到限制，操作系统仍然可以根据“acceptCount”属性设置的数量接受连接。这个参数的默认值是8192。

    Tomcat 8.5 移除了 BIO，默认启用 NIO。`max-connections`参数在BIO模式下默认最大连接数是它的最大线程数(maxThreads，缺省是200)，
    NIO模式下默认是10000 ，APR模式则是8192。

    * **BIO**：通常会为每一个 Web 请求引入单独的线程，当出现高并发量的同时增加线程数，CPU 就需要忙着线程切换损耗性能，所以BIO不合适高吞吐量、高可伸缩的Web 服务器。
    * **NIO**：使用单线程(单个CPU)或者只使用少量的多线程(多CPU)来接受Socket，而由线程池来处理阻塞在 pipe 或者队列里的请求。这样的话，只要操作系统可以接受 TCP 的连接，Web 服务器就可以处理该请求。大大提高了Web 服务器的。

    `max-connections`和`accept-count`的关系为：当连接数达到最大值`max-connections`后，系统会继续接收连接，但不会超过`accept-count`的值。

    这个参数的作用是：

    1. 控制服务器的负载：防止过多的连接导致服务器资源耗尽。
    2. 优化性能：确保服务器能够有效地处理请求。

* `server.tomcat.threads.min-spare`

    用于设置最小工作线程数。最小工作线程数指定了在 Tomcat 服务器启动时或在运行期间应保持的最小空闲线程数。默认是10，可以配置成100。这个参数和`server.tomcat.min-spare-threads`功能我的理解是一样的，但是后者的配置在2.6.x版本的Spring Boot中已经找不到了。

    这有以下几个作用：

    1. 提供快速响应：确保有一些备用线程可用于快速处理新的请求。
    2. 减少线程创建开销：避免在请求到达时频繁地创建新线程。

* `server.tomcat.threads.max`

    **最大工作线程数。按照网上查到的经验值，1核2G的机器最佳配置是200个线程；4核8G的机器，最佳配置是800个线程。默认值是200。**

一个Tomcat总共能受理的最大连接数理论上= **acceptCount+maxConnections**。

对于Tomcat的处理能力需要调整**maxThreads**最大线程数量。

## 3. Tomcat核心参数的形象解释

下面用通过一个形象的比喻，通俗易懂的解释一下tomcat的最大线程数（maxThreads）、最大等待数（acceptCount）和最大连接数（maxConnections）三者之间的关系。

假设Tomcat是一个火锅店，火锅店主要有以下三个角色：

* **acceptCount**，最大等待数，这里类比为火锅店的**排号**数量。
* **maxConnections**，最大连接数，这里类比为火锅店的**餐桌**数量。
* **maxThreads**，最大线程数，这里类比为火锅店的**厨师**数量。

Tomcat接收、处理和响应请求的过程可以类比为顾客用餐的过程：

* 取号：

    * 如果餐厅有空闲的餐桌，顾客就可以直接上桌就餐。类比到Tomcat就是maxConnections连接数还没有满，Tomcat会接收该请求进行处理。
    * 如果没有空桌，顾客就需要进行排号。类比到Tomcat就是maxConnections连接数已满，需要将请求放入等待队列。
        * 如果取号人数没有达到排号的上限，则取号成功。类比到Tomcat就是acceptCount请求队列长队还没有满，可以将请求放置到队列中。
        * 如果已达上限，则取号失败。类比到Tomcat就是请求队列长度已满，此时请求就会被拒绝连接。

* 上桌

    如果餐厅有空闲的餐桌，顾客就可以直接上桌就餐。类比到Tomcat就是maxConnections连接数还没有满，Tomcat会接收该请求进行处理。

* 就餐

    顾客落座之后就会点餐，此时厨房就会去做菜。相比与顾客的数量，厨师的数量肯定是比较少的。如果就餐的人越多，厨师就会越忙不过来，这个时候就需要增加厨师。如果厨师增加到一个上限后，没有办法再新增，此时就会拖慢每个餐桌上菜的速度。也就是说如果Tomcat接收到请求之后如果请求数量超过现有线程数就会新增新的线程来处理新的请求，如果线程数量增加到一定上限之后，也就是达到maxThreads，请求处理的速度就会变慢。

### 4. 压测分析

![](../../assert/修改tomcat核心参数后的压测情况.png)

上面这张图就是我在压测过程中服务器使用`top -H`命令展示的内容，从上面我们可以看到MySQL耗费的大量的CPU和内存资源，说明我们程序的瓶颈主要集中在MySQL上面。

# 定制化内嵌tomcat开发

HTTP keep-alive 也称为 HTTP 长连接。它通过重用一个 TCP 连接来发送/接收多个 HTTP请求，来减少创建/关闭多个 TCP 连接的开销。在Http 1.1版本中，默认是开启Keep-Alive模式的。

HTTP 协议采用 “请求 - 应答” 模式，当使用**普通模式**，即非 KeepAlive 模式时，每个请求 / 应答客户和服务器都要新建一个连接，完成 之后立即断开连接（HTTP 协议为无连接的协议），每次请求都会经过三次握手四次挥手过程，效率较低；当使用**Keep-Alive模式**时，客户端到服务器端的连接不会断开，当出现对服务器的后继请求时，客户端就会复用已建立的连接。

## 1. Keep-Alive的优缺点

* 优点：
    1. 节省了服务端 CPU 和内存使用量
    1. 降低拥塞控制 （TCP 连接减少）
    1. 减少了后续请求的延迟（无需再进行握手）

* 缺点：

    如果在一些请求量比较少的服务上实用Keep-Alive机制，由于请求少，所以请求的连接没必要长期保存连接，如果开启会额外占用服务端的连接数。

## 2. Tomcat 中设置 Keep-Alive（服务端）

在Spring2.x版本中修改Tomcat的配置，代码如下：

```Java
@Configuration
public class WebServerConfiguration {
    
    @Bean
    public TomcatServletWebServerFactory tomcatServletWebServerFactory() {
        TomcatServletWebServerFactory tomcatServletWebServerFactory = new TomcatServletWebServerFactory();
        tomcatServletWebServerFactory.addConnectorCustomizers((connector) -> {
            Http11NioProtocol protocol = (Http11NioProtocol) connector.getProtocolHandler();
            // 定制化KeepAliveTimeout,设置30秒内没有请求则服务端自动断开keepalive链接
            protocol.setKeepAliveTimeout(30000);
            // 当客户端发送超过10000个请求则自动断开keepalive链接
            protocol.setMaxKeepAliveRequests(10000);
        });
        return tomcatServletWebServerFactory;
    }
}
```

* `Keep-Alive:timeout={timeout}`

    如果服务端 Response Header设置了`Keep-Alive:timeout={timeout}`，客户端会就会保持此连接 timeout（单位秒）时间，超时之后关闭连接。

    默认值是使用为`connectionTimeout`属性设置的值 。值为 - 1 表示没有（即无限）超时。

* `Connection close`

    设置通过一个保持活动连接可以服务的请求的最大数量。在发出最大数量的请求之后，连接关闭。 当请求达到最大数量后，通在 Response Header 中增加`Connection close`标识，来主动告诉发送端，连接已经断开了，不能再复用了。客户端接收到此标示后，会销毁连接，再次请求时会重新建立连接。

    `maxKeepAliveRequests="连接可用次数"`，-1 为永不失效。如果未指定，默认为 100。

# 参考文章

* [聚焦Java性能优化 打造亿级流量秒杀系统](https://coding.imooc.com/class/338.html)
* [What is Load Average in Linux?](https://www.digitalocean.com/community/tutorials/load-average-in-linux)
* [What Is Linux Average Load? [6 Monitoring Tools Inside]](https://www.redswitches.com/blog/what-is-load-average-in-linux/)
* [top linux下的任务管理器](https://linuxtools-rst.readthedocs.io/zh-cn/latest/tool/top.html)
* [秒懂：tomcat的maxConnections、maxThreads、acceptCount 图解](https://blog.csdn.net/lililidahaoren/article/details/121696324)
* [Tomcat性能调优](https://juejin.cn/post/6850418121258303501)
* [HTTP keep-alive 二三事](https://lotabout.me/2019/Things-about-keepalive/)
* [细说 Http 中的 Keep-Alive 和 Java Http 中的 Keep-Alive 机制](https://juejin.cn/post/6844903956460601357)
* [Spring Boot 2系列(六十)：Tomcat 中 NIO 模型与启动流程](http://blog.gxitsky.com/2022/02/12/SpringBoot-60-tomcat-nio/)
* [「性能优化系列」Tomcat线程连接池参数优化和JVM参数调优](https://blog.csdn.net/qq_35789269/article/details/122834148)

* [Apache Tomcat 9 Configuration Reference](https://tomcat.apache.org/tomcat-9.0-doc/config/http.html)