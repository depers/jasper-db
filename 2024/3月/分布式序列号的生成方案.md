> 分布式系统/系统设计

> 之前在开发中对这块知识的理解不够深入，想通过这篇文章对目前主流的序列号生成的方案做一个总结。

# 一、UUID

## 1.实现方式

使用JDK自带的UUID的实现，具体API：`UUID.randomUUID()`。

## 2.优点

1. **性能非常高**：本地生成，没有网络消耗。

## 3.缺点

1. **不易于存储**：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用。
2. **信息不安全**：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。
3. **对MySQL索引不利**：如果作为数据库主键，在InnoDB引擎下，UUID的无序性可能会引起数据位置频繁变动，严重影响性能。

# 二、数据库生成

## 1.实现方式

这种方式主要是依赖于数据库自身的自增主键ID来进行实现的。

1. 在MySQL中，设置`auto_increment_increment`和`auto_increment_offset`来保证ID自增。

    查看这两个变量的全局配置

    ```sql
    show global variables like '%auto_inc%';
    ```

    `auto_increment_offset`表示自增长字段从那个数开始，他的取值范围是1 .. 65535。

    `auto_increment_increment`表示自增长字段每次递增的量，其默认值是1，取值范围是1 .. 65535。

2. 设计一张序列号的表结构，如下：

    ```sql
    drop table  if exists `sequence`;
    create table `sequence`(
    	`seq_id` bigint(20) auto_increment comment '主键',
        `seq_name` varchar(20) not null default '' comment '序列号名称',
        primary key (`seq_id`),
        unique key `idx_uni_seq_name`(`seq_name`)
    ) engine=InnoDB comment '序列号表';
    ```

3. 在服务器端代码中，每次需要生成序列号的时候，就执行SQL：

    ```sql
    begin;
    replace into `sequence`(`seq_name`) values ('orderNo');
    select LAST_INSERT_ID();
    commit;
    ```

    `replace into` 跟 `insert into`功能类似，不同点在于：`replace into` 首先尝试插入数据到表中， 1. 如果发现表中已经有此行数据（根据主键或者唯一索引判断）则先删除此行数据，然后插入新的数据。 2. 否则，直接插入新数据。

    要注意的是：插入的数据必须有**主键**或者是**唯一索引**！否则的话，`replace into`会直接插入数据，这将导致表中出现重复的数据。

## 2.优点

1. 非常简单，利用现有数据库系统的功能实现，成本小。
2. ID号单调自增，可以实现一些对ID有特殊要求的业务。

## 3.缺点

1. **强依赖DB，当DB异常时整个系统不可用，属于致命问题**。配置主从复制可以尽可能的增加可用性，但是数据一致性在特殊情况下难以保证。主从切换时的不一致可能会导致重复发号。
2. **ID发号性能瓶颈限制在单台MySQL的读写性能**。

## 4.性能优化

针对单台MySQL的性能瓶颈，我们可以进行水平扩展，使用多台MySQL服务器提供序列号生成的功能，只需要修改每台MySQL自增ID的初始值和递增步长。如下所示：

```
IDServer1:
auto-increment-increment = 2
auto-increment-offset = 1

IDServer2:
auto-increment-increment = 2
auto-increment-offset = 2
```

针对IDServer1，他生成的递增序列是1、3、5...，而IDServer2生成的递增序列是2、4、6...。

优点：减轻了MySQL服务的压力，性能有所提升。

缺点：

1. 后面如果在对服务器进行水平扩展困难。因为刚开始服务器的数量和初始值已经设定好了，如果要新增会变得十分困难，比如我们再加一台服务器，他的初始值我们设置为3，步长设置为2，这样就会导致他生成的序列号和第一台重合。我们需要重新划分这几台服务器的初始值和步长，避免他们生成相同的序列号。
2. ID没有了单调递增的特性，只能趋势递增，这个缺点对于一般业务需求不是很重要，可以容忍。
3. 数据库压力还是很大，每次获取ID都得读写一次数据库，只能靠堆机器来提高性能。

# 三、Redis生成

## 1.实现方式

基于Redis的实现就比较简单了，直接利用`String`数据结构，通过`incr key`命令就可以实现计数。

`incr`命令用于对值进行自增操作，返回的结果分为三种情况：

1. 值不是整数，返回错误。比如`set hello world`，接着`incr hello`。
2. 值是整数，返回自增后的结果，返回结果为1。
3. 键不存在，按照值为0自增，返回结果为1。

**使用Redis的进行计数功能的优势**：许多存储系统和编程语言内部使用CAS机制实现计数功能，会有一定的CPU开销，但在Redis中就不会存在这个问题，因为Redis是单线程架构，任何命令到了Redis服务端都要顺序执行。

## 2.优点

* 不依赖于数据库，灵活方便，且性能优于数据库。
* 生成的序列号是自增的，有利于数据库存储。

## 3.缺点

* 增加了复杂度：引入的新的组件，增加了系统的复杂度。
* 单点故障：如果 Redis 节点出现故障，整个序列号生成系统可能会受到影响，需要采取容错机制来避免单点故障。

# 四、Snowflake算法生成

## 1.原理解析

Snowflake是Twitter在2010年开源的序列号生成算法，理论上snowflake方案的QPS约为409.6w/s，这种分配方式可以保证在任何一个IDC的任何一台机器在任意毫秒内生成的ID都是不同的。下面我们来具体看下这个算法的实现。

![](../../assert/64bit.jpeg)

上图中主要展示了64位长度的Snowflake算法序列号的结构：

* **高位的1bit**不用。
* **41 bit长度**，使用毫秒级别精度，带有一个自定义epoch，41-bit的时间可以表示（1L<<41 / (1000L\* 3600 \* 24 \* 365)=69年的时间。
* **5 bit长度**，用于划分数据中心，可以表示32个IDC。
* **5 bit长度**，用于表示每个数据中心下的机器，可以表示32台机器。
* **12 bit长度**，用于表示自增序列号，可以表示4096个ID，也就是说一毫秒内一台机器可以生成4096个不同的ID。

## 2.具体实现

我是照着Twitter原有的Scala语言的实现做了Java版的一个翻译，具体代码的实现如下：

```java
public class SnowflakeSequence {

    /**
     * Twitter的官方实现
     */

    // 指定初始时间
    private final long epoch = 1711012488360L;

    // 机器ID的最大位长度为5
    private final long workerIdBits = 5L;

    // 数据中心ID的最大长度为5
    private final long dataCenterIdBits = 5L;

    // 序列号的最大长度为12位
    private final long sequenceBits = 12L;

    // 机器ID需要左移的位数为12
    private final long workerIdLeftShift = sequenceBits;

    // 数据中心ID需要左移的位数12+5=17
    private final long dataCenterIdLeftShift = sequenceBits + workerIdBits;

    // 时间戳需要左移的位数 12+5+5=22
    private final long timestampLeftShift = sequenceBits + workerIdBits + dataCenterIdBits;

    // 序列号的掩码，也就是一毫秒内可以生成的序列号的最大值，是4095，也就是2的12次减1
    private final long sequenceMask = -1L ^ (-1L << sequenceBits);

    // 最大的机器ID值，十进制为31
    private final long maxWorkerId = -1L ^ (-1L << workerIdBits);

    // 最大的数据中心ID值，十进制为31
    private final long maxDataCenterId = -1L ^ (-1L << dataCenterIdBits);

    // 初始化上一个时间戳快照值为-1
    private long lastTimestamp = -1L;

    // 初始序列号
    private long sequence = 0L;

    private long workId;
    private long dataCenterId;


    public SnowflakeSequence(long dataCenterId, long workerId) {

        if (workerId > maxWorkerId || workerId < 0) {
            throw new IllegalArgumentException("机器ID不能大于31或者不能小于0");
        }

        if (dataCenterId > maxDataCenterId || dataCenterId < 0) {
            throw new IllegalArgumentException("数据中心ID不能大于31或者不能小于0");
        }

        this.workId = workerId;
        this.dataCenterId = dataCenterId;
    }


    public long getNextNum() {

        // 获取系统时间戳，单位毫秒
        long timestamp = timeGen();

        // 如果当前时间戳下于上次的时间戳，说明发送了时钟回拨，抛出异常，拒绝生成ID
        if (timestamp < lastTimestamp) {
            throw new IllegalStateException("发生了时钟回拨，获取序列号失败");
        }

        // 高并发场景，同一毫秒生成多个ID
        if (timestamp == lastTimestamp) {

            // 确保sequence + 1之后不会溢出，最大值为4095，其实也就是保证1毫秒内最多生成4096个ID值
            sequence = (sequence + 1) & sequenceMask;

            // 如果sequence溢出则变为0，说明1毫秒内并发生成的ID数量超过了4096个，这个时候同1毫秒的第4097个生成的ID必须等待下一毫秒
            if (sequence == 0) {
                // 死循环等待下一个毫秒值，直到比lastTimestamp大
                timestamp = tilNextMillis(lastTimestamp);
            }
        } else {
            // 低并发场景，不同毫秒数的时候生成ID，这里也就是timestamp > lastTimestamp的情况
            sequence = 0;
        }

        lastTimestamp = timestamp;

        return ((timestamp - epoch) << timestampLeftShift) |
            (dataCenterId << dataCenterIdLeftShift) |
            (workId << workerIdLeftShift) |
            sequence;
    }


    private long timeGen() {
        return System.currentTimeMillis();
    }

    private long tilNextMillis(long lastTimestamp) {
        long timestamp = timeGen();
        while (timestamp <= lastTimestamp) {
            timestamp = timeGen();
        }
        return timestamp;
    }


    /**
     * 获取固定长度的字符串
     */
    private String formatRStrZero(String value, int length) {
        StringBuilder sb = new StringBuilder();
        for (int i = 0; i < length / 20 + 1; i++) {
            sb.append("00000000000000000000");
        }
        sb.append(value);
        return sb.substring(sb.length() - length);
    }

    public String getNexSeq(int length) {
        return formatRStrZero(String.valueOf(getNextNum()), length);
    }

    public static void main(String[] args) {
        SnowflakeSequence snowflakeSequence = new SnowflakeSequence(0, 0);
        System.out.println(snowflakeSequence.getNextNum());
        System.out.println(snowflakeSequence.getNexSeq(18));
    }
}
```

## 3.位运算技巧解析

这段代码的逻辑还是十分清晰的。不知道大家和我一样不，看到上面的位运算就觉得很头大，下面我们就对上面几个位运算的技巧做一个阐述：

1. 带符号左移

    `M << n`意味着：

    - `M`的二进制数（补码）向左移动`n`位。
    - 左边（高位）移出部分直接舍弃，右边（低位）移入部分全部补`0`。
    - 移位结果：相当于`M`的值乘以`2`的`n`次方，并且0、正、负数通用。
    - 移动的位数超过了该类型的最大位数，那么编译器会对移动的位数取模，例如`int`移位`33`位，实际上只移动了`33 % 2 = 1`位。

    **在Snowflake算法中将特定区域位置的数进行左移，正好将低位用0补齐，为后续序列号结构的组合做好位置铺垫。**

2. 按位或

    在Snowflake代码中：

    ```java
    return ((timestamp - epoch) << timestampLeftShift) |
                    (dataCenterId << dataCenterIdLeftShift) |
                    (workId << workerIdLeftShift) |
                    sequence;
    ```

    按位与的运算规则是：`0|0=0`，`0|1=1`，`1|0=1` ，`1|1=1`，只要有其中一个位存在1则计算结果是1，只有两个位同时为0的情况下计算结果才是0。主要作用是：**对一个数的部分位赋值为1，只需要和对应位全为0的数做按位或操作就行**，例如`1011 0000`如果低4位想全部赋值为1，那么`10110000 | 00001111`即可得到`1011 1111`。

    **在Snowflake代码先是将不同区域的bit进行按位或操作，从而实现各个区域的拼凑逻辑，完成序列号结构的组合。**

3. 计算n个bit能表示的最大数值

    在Snowflake代码中：

    ```java
    // 机器ID的位长度
    private long workerIdBits = 5L;
    // 最大机器ID -> 31
    private long maxWorkerId = -1L ^ (-1L << workerIdBits);
    ```

    这里的算子是`-1L ^ (-1L << 5L)`，整理运算符的顺序，再使用64 bit的二进制数推演计算过程如下：

    ```shell
    [-1] 的补码         11111111 11111111 11111111 11111111 11111111 11111111 11111111 11111111
    左移5位             11111111 11111111 11111111 11111111 11111111 11111111 11111111 11100000
    [-1] 的补码         11111111 11111111 11111111 11111111 11111111 11111111 11111111 11111111
    异或                ----------------------------------------------------------------------- ^ 
    结果的补码           00000000 00000000 00000000 00000000 00000000 00000000 00000000 00011111  （十进制数 2^0 + 2^1 + 2^2 + 2^3 + 2^4 = 31）
    ```

    这样就能计算出5 bit能表示的最大数值n，n为整数并且`0 <= n <= 31`，即0、1、2、3...31。Worker ID和Data Center ID部分的最大值就是使用这种组合运算得出的。

4. 用固定位的最大值作为Mask避免溢出

    在Snowflake代码中：

    ```Java
    // 序列号的最大长度为12位
    private final long sequenceBits = 12L;
    // 序列号的掩码，也就是一毫秒内可以生成的序列号的最大值，是4095，也就是2的12次减1
    private final long sequenceMask = -1L ^ (-1L << sequenceBits);
    // 初始序列号
    private long sequence = 0L;
    ...
    sequence = (sequence + 1) & sequenceMask;
    ```

    从上面的变量声明中我们可以看到，序列号区域12位bit能够生成的最大数是4095，**我们要保证每一毫秒生成的序列号不能大于4095，如果大于了那12个bit位就办法存储这个数字了。**

    假设`sequence`当前值为`4095`，推演一下计算过程：

    ```shell
    [4095] 的补码                 00000000 00000000 00000000 00000000 00000000 00000000 00000111 11111111
    [sequence + 1] 的补码         00000000 00000000 00000000 00000000 00000000 00000000 00001000 00000000
    按位与                        ----------------------------------------------------------------------- &
    计算结果                      00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000（十进制数：0）
    ```

    这里你就看到效果了吧，也就是**超过4095的数字通过按位与会被重置为0，没有超过4095的数经过按位与还是它本身。**

## 4.优点

- 毫秒数在高位，自增序列在低位，整个ID都是趋势递增的。
- 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的。
- 可以根据自身业务特性分配bit位，非常灵活。

## 5.缺点

* 强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。

## 6.优化版Snowflake算法

Snowflake算法有几个比较大的问题：

1. 低并发场景会产生连续偶数，原因是低并发场景系统时钟总是走到下一个毫秒值，导致序列号重置为`0`。

    这个问题比较好解决，直接使用随机数进行解决就行，直接看代码：

    原来的版本：

    ```java
    // 高并发场景，同一毫秒生成多个ID
    if (timestamp == lastTimestamp) {
    
        // 确保sequence + 1之后不会溢出，最大值为4095，其实也就是保证1毫秒内最多生成4096个ID值
        sequence = (sequence + 1) & sequenceMask;
    
        // 如果sequence溢出则变为0，说明1毫秒内并发生成的ID数量超过了4096个，这个时候同1毫秒的第4097个生成的ID必须等待下一毫秒
        if (sequence == 0) {
            // 死循环等待下一个毫秒值，直到比lastTimestamp大
            timestamp = tilNextMillis(lastTimestamp);
        }
    } else {
        // 低并发场景，不同毫秒数的时候生成ID，这里也就是timestamp > lastTimestamp的情况
        sequence = 0;
    }
    ```

    更新后的版本（美团Leaf的代码）：

    ```java
    if (lastTimestamp == timestamp) {
        sequence = (sequence + 1) & sequenceMask;
        if (sequence == 0) {
            //seq 为0的时候表示是下一毫秒时间开始对seq做随机
            sequence = RANDOM.nextInt(100);
            timestamp = tilNextMillis(lastTimestamp);
        }
    } else {
        //如果是新的ms开始
        sequence = RANDOM.nextInt(100);
    }
    ```

    采用这种方案之后会稍微减少同一个毫秒内能产生的最大ID数量。

2. 依赖系统时钟，时钟回拨会拒绝生成新的ID（直接抛出异常）。

    这里采取的方案就是对时钟回拨进行一定时间的等待。

    原来的版本：

    ```java
     // 如果当前时间戳小于上次的时间戳，说明发送了时钟回拨，抛出异常，拒绝生成ID
    if (timestamp < lastTimestamp) {
        throw new IllegalStateException("发生了时钟回拨，获取序列号失败");
    }
    ```

    更新后的版本（美团Leaf的代码）：

    ```java
    if (timestamp < lastTimestamp) {
        long offset = lastTimestamp - timestamp;
        if (offset <= 5) {
            try {
                wait(offset << 1);
                timestamp = timeGen();
                if (timestamp < lastTimestamp) {
                    return new Result(-1, Status.EXCEPTION);
                }
            } catch (InterruptedException e) {
                LOGGER.error("wait interrupted");
                return new Result(-2, Status.EXCEPTION);
            }
        } else {
            return new Result(-3, Status.EXCEPTION);
        }
    }
    ```

    按照上面代码的逻辑，如果时钟回拨的范围小于等于5毫秒，就等待10毫秒，重新获取当前时间。

3. Woker ID和Data Center ID的管理比较麻烦，特别是同一个服务的不同集群节点需要保证每个节点的Woker ID和Data Center ID组合唯一。

    这个问题在小型项目中我们可以通过数据字段配置或是配置文件进行固定设置。如果在大规模项目中可以借鉴美团leaf-snowflake的实现，下面一节就会介绍这部分内容。

# 五、美团leaf的实现分析

## leaf-snowflake

### 1. 解决的问题

1. 采用数据库、Redis生成的序列号是自增可计算的，如果我们在订单号场景使用这个序列号，那么其他人就可以通过订单号统计我们一段时间的订单量，这个是不能接受的。
2. 针对第一问题，我们其实可以采用Snowflake算法来生成，它的序列号不具备自增可计算的的特性，如果采用Snowflake算法，在大规模项目中，手动配置工作机器Id和数据中心Id成本太高了，而且会出错。

### 2.解决方案

使用**Zookeeper持久顺序节点的特性**自动对snowflake节点配置wokerID，在leaf中美团将工作机器Id和数据中心Id合并成了workID，一共10个bit位。

### 3.源代码分析

leaf中生成workID的代码在[com.sankuai.inf.leaf.snowflake.SnowflakeZookeeperHolder#init](https://github.com/Meituan-Dianping/Leaf/blob/master/leaf-core/src/main/java/com/sankuai/inf/leaf/snowflake/SnowflakeZookeeperHolder.java)方法上，大家可以点开看下。代码的大体逻辑如下图：

![](../../assert/leaf-snowflake.svg)

### 3.zk持久顺序节点

zookeeper 中的所有存储的数据是由 znode 组成的，节点也称为 znode，并以 key/value 形式存储数据。整体结构类似于 linux 文件系统的模式以树形结构存储。其中根路径以 `/`开头。

看下这段代码：

```Java
/**
 * 创建持久顺序节点 ,并把节点数据放入 value
 *
 * @param curator
 * @return
 * @throws Exception
 */
private String createNode(CuratorFramework curator) throws Exception {
    try {
        return curator.create().creatingParentsIfNeeded().withMode(CreateMode.PERSISTENT_SEQUENTIAL).forPath(PATH_FOREVER + "/" + listenAddress + "-", buildData().getBytes());
    } catch (Exception e) {
        LOGGER.error("create node error msg {} ", e.getMessage());
        throw e;
    }
}
```

上面这段代码中`CreateMode.PERSISTENT_SEQUENTIAL`表示我们创建了一个持久化的顺序节点，这个顺序节点的全路径大概长这样：`/snowflake/leaf/forever/127.0.0.1:8080-0000000001`，值得注意的是我们在代码中传入的节点path是`/snowflake/leaf/forever/127.0.0.1:8080-`，节点创建之后真实的节点名称后面会被拼接10位长度的有序数值，也就是例子中的`0000000001`，这个就是zk帮忙我们生成的唯一有序的workID。

## leaf-segment

### 1.解决的问题

采用数据库生成方式时，每次获取ID都得读写一次数据库，造成数据库压力大。

### 2.解决方案

采用双号段的设计，第一个序列号段用来满足正常的使用，另一个序列号段用来做预备号段。当第一个号段的使用率超过了当前号段的10%，就会提前生成下一个号段的数据。通过这种方式第一避免了每次读取数据库造成数据库压力过大，第二通过双号段实现了非阻塞获取号段，避免了实时获取号段造成的阻塞。

### 3.号段的结构

先看代码中的数据结构：

* `SegmentBuffer`，父段

    ```java
    private String key; // 业务标识
    private Segment[] segments; // 双buffer
    private volatile int currentPos; // 当前的使用的segment的index
    private volatile boolean nextReady; // 下一个segment是否处于可切换状态
    private volatile boolean initOk; // 是否初始化完成
    private final AtomicBoolean threadRunning; // 线程是否在运行中
    private final ReadWriteLock lock; // 读写锁
    
    private volatile int step; // 根据号段的使用时间动态换算的步长
    private volatile int minStep; // 数据库中的步长
    private volatile long updateTimestamp; // 上次更新的时间
    ```

* `Segment`，子段

    ```java
    private AtomicLong value = new AtomicLong(0); // 当前值
    private volatile long max; // 当前段的最大值
    private volatile int step; // 步长
    private SegmentBuffer buffer; // 父级段
    ```

* `LeafAlloc`，数据库`Entity`

    ```java
    private String key;
    private long maxId;
    private int step;
    private String updateTime;
    ```

下面是我按照上述结构画的结构图，可以对照看下，这里唯一看起来有点绕的地方就是`SegmentBuffer`中的`segments`数组中的`Segment`，`Segment`类中又引用了`SegmentBuffer`类的`buffer`属性。为什么这样写呢？通过分析代码后我发现作者这样写的原因是**为了能通沟通字段获取到父段，并修改父段的属性才这样写的**。

![](../../assert/leaf-segment双buffer结构.svg)

### 4.表结构设计

```sql
CREATE DATABASE leaf;
CREATE TABLE `leaf_alloc` (
  `biz_tag` varchar(128)  NOT NULL DEFAULT '' COMMENT '业务标签',
  `max_id` bigint(20) NOT NULL DEFAULT '1' COMMENT '初始id',
  `step` int(11) NOT NULL COMMENT '增长步长',
  `description` varchar(256)  DEFAULT NULL COMMENT '描述',
  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  PRIMARY KEY (`biz_tag`)
) ENGINE=InnoDB;

-- 投产之前需要预埋数据
insert into leaf_alloc(biz_tag, max_id, step, description) values('leaf-segment-test', 1, 2000, 'Test leaf Segment Mode Get Id');
```

### 5.代码设计

在源码中主要的代码逻辑在com.sankuai.inf.leaf.segment.SegmentIDGenImpl类中，我直接将注释的代码放出来：

```java
@Override
public boolean init() {
    logger.info("Init ...");
    // 确保加载到kv后才初始化成功
    updateCacheFromDb();
    initOK = true;
    // 每过一分钟就对内存中的缓存做一次整理
    updateCacheFromDbAtEveryMinute();
    return initOK;
}

/**
* 每分钟将数据库的信息更新到缓存中
*/
private void updateCacheFromDbAtEveryMinute() {
    ScheduledExecutorService service = Executors.newSingleThreadScheduledExecutor(new ThreadFactory() {
        @Override
        public Thread newThread(Runnable r) {
            Thread t = new Thread(r);
            t.setName("check-idCache-thread");
            t.setDaemon(true);
            return t;
        }
    });
    service.scheduleWithFixedDelay(new Runnable() {
        @Override
        public void run() {
            updateCacheFromDb();
        }
    }, 60, 60, TimeUnit.SECONDS);
}

private void updateCacheFromDb() {
    logger.info("update cache from db");
    StopWatch sw = new Slf4JStopWatch();
    try {
        // 查询数据库的所有业务标签
        List<String> dbTags = dao.getAllTags();
        if (dbTags == null || dbTags.isEmpty()) {
            return;
        }

        // 已经缓存的业务标签
        List<String> cacheTags = new ArrayList<String>(cache.keySet());

        // 查询数据库中所有的业务标签放到这里
        Set<String> insertTagsSet = new HashSet<>(dbTags);

        // 已经缓存的标签
        Set<String> removeTagsSet = new HashSet<>(cacheTags);
        //db中新加的tags灌进cache，将已经缓存的业务标签从待插入集合中删除
        for(int i = 0; i < cacheTags.size(); i++){
            String tmp = cacheTags.get(i);
            if(insertTagsSet.contains(tmp)){
                // 从准备插入的业务标签中删除已经在内存缓存中的业务标签
                insertTagsSet.remove(tmp);
            }
        }
        // 将数据库中新增的标签放到缓存中
        for (String tag : insertTagsSet) {
            SegmentBuffer buffer = new SegmentBuffer();
            buffer.setKey(tag);
            Segment segment = buffer.getCurrent();
            segment.setValue(new AtomicLong(0));
            segment.setMax(0);
            segment.setStep(0);
            cache.put(tag, buffer);
            logger.info("Add tag {} from db to IdCache, SegmentBuffer {}", tag, buffer);
        }

        // 如果数据库中存在该业务标识，说明该业务标识还在数据，从待删除的标签集合中删除在使用的业务标签
        for(int i = 0; i < dbTags.size(); i++){
            String tmp = dbTags.get(i);
            if(removeTagsSet.contains(tmp)){
                removeTagsSet.remove(tmp);
            }
        }
        //cache中已失效的tags从cache删除
        for (String tag : removeTagsSet) {
            cache.remove(tag);
            logger.info("Remove tag {} from IdCache", tag);
        }
    } catch (Exception e) {
        logger.warn("update cache from db exception", e);
    } finally {
        sw.stop("updateCacheFromDb");
    }
}

@Override
public Result get(final String key) {
    if (!initOK) {
        return new Result(EXCEPTION_ID_IDCACHE_INIT_FALSE, Status.EXCEPTION);
    }
    if (cache.containsKey(key)) {
        SegmentBuffer buffer = cache.get(key);
        // 双重检测机制
        if (!buffer.isInitOk()) {
            // 只能有一个线程进去更新子段
            synchronized (buffer) {
                if (!buffer.isInitOk()) {
                    try {
                        updateSegmentFromDb(key, buffer.getCurrent());
                        logger.info("Init buffer. Update leafkey {} {} from db", key, buffer.getCurrent());
                        buffer.setInitOk(true);
                    } catch (Exception e) {
                        logger.warn("Init buffer {} exception", buffer.getCurrent(), e);
                    }
                }
            }
        }
        // 从内存缓存中获取序列号
        return getIdFromSegmentBuffer(cache.get(key));
    }
    return new Result(EXCEPTION_ID_KEY_NOT_EXISTS, Status.EXCEPTION);
}

public void updateSegmentFromDb(String key, Segment segment) {
    StopWatch sw = new Slf4JStopWatch();
    SegmentBuffer buffer = segment.getBuffer();
    LeafAlloc leafAlloc;
    // 第一次该子段还没有被初始化
    if (!buffer.isInitOk()) {
        leafAlloc = dao.updateMaxIdAndGetLeafAlloc(key);
        buffer.setStep(leafAlloc.getStep());
        buffer.setMinStep(leafAlloc.getStep());//leafAlloc中的step为DB中的step
    } else if (buffer.getUpdateTimestamp() == 0) {
        // 第二次更新这个字段的时候，要更新他的更新时间
        leafAlloc = dao.updateMaxIdAndGetLeafAlloc(key);
        buffer.setUpdateTimestamp(System.currentTimeMillis());
        buffer.setStep(leafAlloc.getStep());
        buffer.setMinStep(leafAlloc.getStep());//leafAlloc中的step为DB中的step
    } else {
        // 第三次和后面几次，获取该子段使用的持续时间
        long duration = System.currentTimeMillis() - buffer.getUpdateTimestamp();
        int nextStep = buffer.getStep();
        // 子段的持续时间小于15分钟
        if (duration < SEGMENT_DURATION) {
            // 如果当前子段的步长大于50万
            if (nextStep * 2 > MAX_STEP) {
                //do nothing
            } else {
                // 否则将步长扩大为原来的两倍
                nextStep = nextStep * 2;
            }
            // 子段的持续时间小于30分钟
        } else if (duration < SEGMENT_DURATION * 2) {
            //do nothing with nextStep
        } else {
            // 子段的持续时间大于30分钟
            // 如果步长的一半大于等于数据库的步长，新的步长设置为原步长的一半，否则按原步长走
            nextStep = nextStep / 2 >= buffer.getMinStep() ? nextStep / 2 : nextStep;
        }
        logger.info("leafKey[{}], step[{}], duration[{}mins], nextStep[{}]", key, buffer.getStep(), String.format("%.2f",((double)duration / (1000 * 60))), nextStep);
        LeafAlloc temp = new LeafAlloc();
        temp.setKey(key);
        temp.setStep(nextStep);
        // 根据子段号段的使用时间，对获取号段的步长进行控制，用自己换算的步长更新数据库
        leafAlloc = dao.updateMaxIdByCustomStepAndGetLeafAlloc(temp);
        buffer.setUpdateTimestamp(System.currentTimeMillis());
        buffer.setStep(nextStep);
        buffer.setMinStep(leafAlloc.getStep());//leafAlloc的step为DB中的step
    }
    // must set value before set max
    long value = leafAlloc.getMaxId() - buffer.getStep(); // 这个value就是目前这个段的当前值
    segment.getValue().set(value);
    segment.setMax(leafAlloc.getMaxId());
    segment.setStep(buffer.getStep());
    sw.stop("updateSegmentFromDb", key + " " + segment);
}

public Result getIdFromSegmentBuffer(final SegmentBuffer buffer) {
    while (true) {
        // 获取读锁
        buffer.rLock().lock();
        try {
            final Segment segment = buffer.getCurrent();
            // 如果下一个子段没有准备好 && 当前子段已使用号码数量超过了10% && 当前子段没有在使用
            if (!buffer.isNextReady() && (segment.getIdle() < 0.9 * segment.getStep()) && buffer.getThreadRunning().compareAndSet(false, true)) {
                // 异步执行
                service.execute(new Runnable() {
                    @Override
                    public void run() {
                        // 获取下一个子段
                        Segment next = buffer.getSegments()[buffer.nextPos()];
                        boolean updateOk = false;
                        try {
                            updateSegmentFromDb(buffer.getKey(), next);
                            updateOk = true;
                            logger.info("update segment {} from db {}", buffer.getKey(), next);
                        } catch (Exception e) {
                            logger.warn(buffer.getKey() + " updateSegmentFromDb exception", e);
                        } finally {
                            // 若子段和父段更新成功，更新段的信息
                            if (updateOk) {
                                buffer.wLock().lock();
                                buffer.setNextReady(true);
                                buffer.getThreadRunning().set(false);
                                buffer.wLock().unlock();
                            } else {
                                buffer.getThreadRunning().set(false);
                            }
                        }
                    }
                });
            }
            long value = segment.getValue().getAndIncrement();
            if (value < segment.getMax()) {
                return new Result(value, Status.SUCCESS);
            }
        } finally {
            buffer.rLock().unlock();
        }
        // 如果正在更新父段的下一个子段，这里等一会再获取写锁
        waitAndSleep(buffer);
        buffer.wLock().lock();
        try {
            final Segment segment = buffer.getCurrent();
            long value = segment.getValue().getAndIncrement();
            if (value < segment.getMax()) {
                return new Result(value, Status.SUCCESS);
            }
            // 当前值已经超过最大值，使用下一个子段
            if (buffer.isNextReady()) {
                buffer.switchPos();
                buffer.setNextReady(false);
            } else {
                logger.error("Both two segments in {} are not ready!", buffer);
                return new Result(EXCEPTION_ID_TWO_SEGMENTS_ARE_NULL, Status.EXCEPTION);
            }
        } finally {
            buffer.wLock().unlock();
        }
    }
}

/**
 * 等待
 */
private void waitAndSleep(SegmentBuffer buffer) {
    int roll = 0;
    while (buffer.getThreadRunning().get()) {
        roll += 1;
        if(roll > 10000) {
            try {
                TimeUnit.MILLISECONDS.sleep(10);
                break;
            } catch (InterruptedException e) {
                logger.warn("Thread {} Interrupted",Thread.currentThread().getName());
                break;
            }
        }
    }
}
```

### 6.源码设计反思

1. `AtomicBoolean`和`volatile boolean`的区别是什么？

    首先我们先来看下`volatile`关键字，这个关键字**保证了线程安全的有序性和可见性**，但是他并**不能保证原子性**。下面我们看下这段代码：

    ```Java
    public class VolatileExample implements Runnable{
    
        public static volatile int inc = 0;
    
        @Override
        public void run() {
            for (int i = 0; i < 10000; i++) {
                inc++;
            }
        }
    
        public static void main(String[] args) throws InterruptedException {
           Thread[] threads = new Thread[10];
    
           for (int i = 0; i < 10; i++) {
               threads[i] = new Thread(new VolatileExample());
               threads[i].start();
           }
    
           for (int i = 0; i < 10; i++) {
               threads[i].join();
           }
    
            System.out.println(inc);
        }
    }
    ```

    大家猜一猜控制台输出的`inc`的值是多少？是100000吗？正确答案是这个值不是100000，它远比100000要小，而且每次都不同。

    在leaf-segment的这段代码中，`volatile`修饰的变量只是被当做一个状态标志来使用，确保了该变量在多线程环境下的可见性。

    而`AtomicBoolean`却是利用了CAS原理（关于CAS的知识我专门写了一篇博客，可以参考：[《Java中CAS机制的讨论》](http://www.bravedawn.cn/details.html?aid=8501)），这种方式比锁有着更优越的性能，而且具备原子性的特点。在leaf-segment的这段代码中，`AtomicBoolean`修饰的变量利用CAS原理实现的对该变量的原子性操作。

    综上所述，`volatile`保证的是所修饰变量的可见性，而`AotmicBoolean`保证的是所修饰变量的操作的原子性。

2. `ReentrantReadWriteLock`读写锁的使用场景是什么？

    在leaf-segment的`SegmentBuffer`类中使用了`ReetrantReadWriteLock`读写锁，因为SegmentBuffer中的数据有**读多写少的特性**，这里触发的写操作就是一个号段的号码使用数量超过该号段的10%时，提前预存下一个号段的数据。如果针对读操作和写操作都进行互斥控制，大量的锁竞争是十分消耗性能的。而且读操作本身并不对数据的完整性造成破坏，所以采用读写锁有效避免的大量读请求下锁竞争导致的性能损耗。

    在这里读写锁的访问控制情况如下：

    |      | 读     | 写   |
    | ---- | ------ | ---- |
    | 读   | 非阻塞 | 阻塞 |
    | 写   | 阻塞   | 阻塞 |

# 参考文档

* [冷饭新炒：理解Snowflake算法的实现原理](https://juejin.cn/post/6859155994061373448)
* [Leaf——美团点评分布式ID生成系统](https://tech.meituan.com/2017/04/21/mt-leaf.html)
* [Leaf：美团分布式ID生成服务开源](https://tech.meituan.com/2019/03/07/open-source-project-leaf.html)
* [Java 之 volatile 详解](https://juejin.cn/post/6844903593930293261?searchId=2024040316434004B447BCCA0700895F5F)
* [《实战Java高并发程序设计》第一版 葛一鸣/郭超](https://book.douban.com/subject/26663605/)
* [《Java并发编程之美》翟陆续/薛宾田](https://book.douban.com/subject/30351286/)